{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5IlgEnKCSx8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **DCGAN implementation of MNIST dataset**\n",
        "\n",
        "Software Requirements:\n",
        "python 3\n",
        "\n",
        "library requirements \n",
        "1.   Torch\n",
        "2.   Torchvision\n",
        "3.   Matplotlib\n",
        "4.   tensorboardX\n",
        "5.    numpy\n",
        "6.   Pillow\n",
        "\n",
        "\n",
        "Running Instructions:\n",
        "1. Install all libraries\n",
        "2. Run the Code cell below \n",
        "\n",
        "DCGAN architecture Details\n",
        "\n",
        "![DCGAN architecture details](https://raw.githubusercontent.com/znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN/master/pytorch_DCGAN.png)\n",
        "\n",
        "\n",
        "Generated images after a few epochs\n",
        "\n",
        "![alt text](https://i.imgur.com/Vp1w3KS.png)\n",
        "\n",
        "\n",
        "**References**:\n",
        "\n",
        "1. [DCGAN Paper](https://arxiv.org/pdf/1511.06434.)\n",
        "2. [MNIST- celebA implementation](https://github.com/znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN)\n",
        "3. [utility File, GAN tutorial](https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "LGt4QJHUWkoT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "logger utility class to save images , models and log tensorboard data\n"
      ]
    },
    {
      "metadata": {
        "id": "KnbfbabsthKO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from tensorboardX import SummaryWriter\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "# utility class to show image plots , save model, and log tensorboard Data\n",
        "class Logger:\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "    \n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        var_class = torch.autograd.Variable\n",
        "        if type(d_error) == var_class:\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if type(g_error) == var_class:\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "\n",
        "        if format == 'NHWC':\n",
        "            images = images.transpose(1, 3)\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(16, 16))\n",
        "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        if plot_horizontal:\n",
        "            display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "\n",
        "        var_class = torch.autograd.Variable\n",
        "        if type(d_error) == var_class:\n",
        "            d_error = d_error.data.cpu().numpy()[0]\n",
        "        if type(g_error) == var_class:\n",
        "            g_error = g_error.data.cpu().numpy()[0]\n",
        "        if type(d_pred_real) == var_class:\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if type(d_pred_fake) == var_class:\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "\n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch, num_epochs, n_batch, num_batches)\n",
        "        )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LnNdivABtvAw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CODE FROM HERE"
      ]
    },
    {
      "metadata": {
        "id": "XbUQf8U3O8z7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#DCGAN implementation for MNIST\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.autograd Pimport Variable\n",
        "from IPython import display\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "import numpy as np\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from tensorboardX import SummaryWriter\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "                \n",
        "#data generator function to create MNIST data\n",
        "#uses inbuilt dataloader from pytorch datasets , downloads the dataset if necessary \n",
        "def data_generator():\n",
        "    # applies transfroms to each image to convert it to a valid format by resizing and bringing it into a (-1,1) range\n",
        "    compose = transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((.5,.5,.5),(.5,.5,.5))\n",
        "    ])\n",
        "    out_dir='{}/dataset'.format('MNIST')\n",
        "    return datasets.MNIST(out_dir,True,compose,download=True)\n",
        "\n",
        "data = data_generator()\n",
        "batch_size = 100\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "num_batches = len(data_loader)\n",
        "\n",
        "\n",
        "#discriminator net \n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "# Network for discriminator is created in this part of code\n",
        "# Four layers have 1, 128, 256, 512, 1024 and 1 channels respectively.\n",
        "# Batch Normalisation is applied to  all hidden layers.\n",
        "# LeakyReLU with negetive slope 0.2 is applied to all the layers except the output layer. \n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        # First convolutional layer takes 1 channel and returns 128 channels, applies a 4*4 kernel with a padding of 1 and stride of 2.\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1,128,4,2,1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        # Second convolutional layer takes 128 channel input and returns 256 channels, applies a 4*4 kernel with a padding of 1 and stride of 2.\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256,4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        # Third convolutional layer takes 256 channels and returns 512 channels, applies a 4*4 kernel with a padding of 1 and stride of 2.\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256,512, 4, 2, 1,bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        # Fourth convolutional layer takes 512 channels and returns 1024 channels,applies a 4*4 kernel with a padding of 1 and stride of 2. \n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        # Linear network is used for the last layer.\n",
        "        # Sigmoid activation function is  used. \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024*4*4, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        # Flatten and apply sigmoid\n",
        "        x = x.view(-1, 1024*4*4)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "#generatorNet Class contains our generator network which inherits the nn.Module \n",
        "class generatorNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(generatorNet, self).__init__()\n",
        "        #a liner layer to convert a noise vector of size 100 to a size of 1024*4*4\n",
        "        self.linear = torch.nn.Linear(100, 1024 * 4 * 4)\n",
        "        \n",
        "        #you can view the architecture in a more feasible manner in the image provided\n",
        "        #ReLu activation has been used in every layer and A batchnorm has been applied after the output of Deconvolutional layer\n",
        "        \n",
        "        #first deconvolutional layer which takes 1024 input channels and returns 512 output channels , applies a 4*4 kernel with a padding of 1 and stride of 2.         \n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(1024,512, 4, 2, 1, bias=False ),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        #second deconvolutional layer which takes 512 input channels and returns 256 output channels , applies a 4*4 kernel with a padding of 1 and stride of 2. \n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        #fourth deconvolutional layer which takes 256 input channels and returns 128 output channels , applies a 4*4 kernel with a padding of 1 and stride of 2. \n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128,4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        #fifth deconvolutional layer which takes 128 input channels and returns 1 output channel , applies a 4*4 kernel with a padding of 1 and stride of 2.\n",
        "        #we dont apply batchnorm to this deconvolutional layer.\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False)\n",
        "        )\n",
        "        \n",
        "        #tanh activator for the output of fifth deconvolutional layer. \n",
        "        self.out = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Project and reshape\n",
        "        x = self.linear(x)\n",
        "        x = x.view(x.shape[0], 1024, 4, 4)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.deconv4(x)\n",
        "        # Apply Tanh\n",
        "        return self.out(x)\n",
        "\n",
        "\n",
        "#noise generator takes size as a parameter and generates a noise vector with size 100   \n",
        "def noise(size):\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    if torch.cuda.is_available(): return n.cuda()\n",
        "    return n\n",
        "\n",
        "\n",
        "#weight initialization function to initialize the weights of both the generator and discriminator   \n",
        "def init_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(0.00, 0.02)\n",
        "# Get instance of generator and discriminator network \n",
        "generator = generatorNet()\n",
        "discriminator = DiscriminatorNet()\n",
        "# Initialise the weights\n",
        "generator.apply(init_weights)\n",
        "discriminator.apply(init_weights)\n",
        "\n",
        "#set it to cuda if cuda enabled GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "\n",
        "# both the networks use Adam optimizer with learning rate of 0.0002 and beta of 0.5 with NO weight decay.\n",
        "d_optimizer = Adam(discriminator.parameters(),lr=0.0002, betas=(0.5,0.999))\n",
        "g_optimizer = Adam(generator.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "\n",
        "\n",
        "#A binay cross entropy loss has been used as its very similar to the loss described in the DCGAN paper.\n",
        "loss = nn.BCELoss()\n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "#this function takes the size as parameter and generates a vector of 1s with the given size , this vector will be our real data target.\n",
        "def real_data_target(size):\n",
        "    if torch.cuda.is_available():\n",
        "        return Variable(torch.ones(size,1)).cuda()\n",
        "    return Variable(torch.ones(size,1))\n",
        "\n",
        "#this function takes the size as parameter and generates a vector of 0s with the given size , this vector will be our fake data target.\n",
        "def fake_data_target(size):\n",
        "    if torch.cuda.is_available():\n",
        "        return Variable(torch.zeros(size,1)).cuda()\n",
        "    return Variable(torch.zeros(size,1))\n",
        "\n",
        "#training function for the discriminator\n",
        "#takes input as the optimizer , real image data , and the generated (fake) images data.\n",
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    #set the gradients to zero before optimization\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #get the prediction from the discriminator for the real data and calculate the error by comparing it to the real data target \n",
        "    prediction_real = discriminator(real_data)\n",
        "    error_real = loss(prediction_real,real_data_target(real_data.size(0)))\n",
        "    #calculate all the gradients going backward for the disriminator\n",
        "    error_real.backward()\n",
        "\n",
        "    #get the prediction from the discriminator for the fake data and calculate the error by comparing it to the fake data target \n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    error_fake = loss(prediction_fake,fake_data_target(real_data.size(0)))\n",
        "    #calculate all the gradients going backward for the generator \n",
        "    error_fake.backward()\n",
        "\n",
        "     #backpropogate the weight and optimize both the nets\n",
        "    optimizer.step()\n",
        "\n",
        "    return error_real+error_fake,prediction_real,prediction_fake\n",
        "  \n",
        "  \n",
        "#training function for the generator\n",
        "def train_generator(optimizer,fake_data):\n",
        "    optimizer.step()\n",
        "    # get predictions from discriminator by feeding fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "    # calcuate the error of prediction by comparing it to real data target\n",
        "    error = loss(prediction,real_data_target(prediction.size(0)))\n",
        "    # backpropagate the error and update the weights\n",
        "    error.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    return error\n",
        "\n",
        "#logger configuratiom.\n",
        "logger = Logger(model_name='DCGAN', data_name='MNIST')\n",
        "\n",
        "#generate noise samples for testing.\n",
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)\n",
        "\n",
        "#trainig loop for the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    #loop through one batch of data in ths loop.\n",
        "    for n_batch, (real_batch, _) in enumerate(data_loader):\n",
        "\n",
        "        real_data = Variable(real_batch)\n",
        "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_data.size(0))).detach()\n",
        "        # Train the discriminatorNet\n",
        "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
        "                                                                real_data, fake_data)\n",
        "\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_batch.size(0)))\n",
        "        # Train Generator \n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "        # Log error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "\n",
        "        # Display Progress\n",
        "        if (n_batch) % 10 == 0:\n",
        "            display.clear_output(True)\n",
        "            # Display Images\n",
        "            test_images = generator(test_noise).data.cpu()\n",
        "            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )\n",
        "        # Save the model that has been trained \n",
        "        logger.save_models(generator, discriminator, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}